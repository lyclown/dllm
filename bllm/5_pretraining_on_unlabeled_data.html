<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>在无标签数据上进行预训练 | 大模型知识库</title>
    <meta name="description" content="A VitePress Site">
    <meta name="generator" content="VitePress v1.5.0">
    <link rel="preload stylesheet" href="./assets/style.DIk0o_HS.css" as="style">
    <link rel="preload stylesheet" href="./vp-icons.css" as="style">
    
    <script type="module" src="./assets/app.3c7bsFzO.js"></script>
    <link rel="preload" href="./assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="./assets/chunks/theme.Q2YBgaya.js">
    <link rel="modulepreload" href="./assets/chunks/framework.DOxSgbfx.js">
    <link rel="modulepreload" href="./assets/bllm_5_pretraining_on_unlabeled_data.md.DJ9O5TGa.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-04082acb><!--[--><!--]--><!--[--><span tabindex="-1" data-v-2abd97fb></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-2abd97fb> Skip to content </a><!--]--><!----><header class="VPNav" data-v-04082acb data-v-4d8a2a03><div class="VPNavBar" data-v-4d8a2a03 data-v-d662bdbc><div class="wrapper" data-v-d662bdbc><div class="container" data-v-d662bdbc><div class="title" data-v-d662bdbc><div class="VPNavBarTitle has-sidebar" data-v-d662bdbc data-v-851315c7><a class="title" href="./" data-v-851315c7><!--[--><!--]--><!----><span data-v-851315c7>大模型知识库</span><!--[--><!--]--></a></div></div><div class="content" data-v-d662bdbc><div class="content-body" data-v-d662bdbc><!--[--><!--]--><div class="VPNavBarSearch search" data-v-d662bdbc><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-d662bdbc data-v-d3871c33><span id="main-nav-aria-label" class="visually-hidden" data-v-d3871c33> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="./" tabindex="0" data-v-d3871c33 data-v-abb8c4e8><!--[--><span data-v-abb8c4e8>首页</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="./markdown-examples.html" tabindex="0" data-v-d3871c33 data-v-abb8c4e8><!--[--><span data-v-abb8c4e8>示例</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-d662bdbc data-v-cc58c11e><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-cc58c11e data-v-e81c969b data-v-5d4aee43><span class="check" data-v-5d4aee43><span class="icon" data-v-5d4aee43><!--[--><span class="vpi-sun sun" data-v-e81c969b></span><span class="vpi-moon moon" data-v-e81c969b></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-d662bdbc data-v-d3159530 data-v-c5f7a4ac><!--[--><a class="VPSocialLink no-icon" href="https://github.com/vuejs/vitepress" aria-label="github" target="_blank" rel="noopener" data-v-c5f7a4ac data-v-acb7c684><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-d662bdbc data-v-42c56eeb data-v-6c050606><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-6c050606><span class="vpi-more-horizontal icon" data-v-6c050606></span></button><div class="menu" data-v-6c050606><div class="VPMenu" data-v-6c050606 data-v-a0042935><!----><!--[--><!--[--><!----><div class="group" data-v-42c56eeb><div class="item appearance" data-v-42c56eeb><p class="label" data-v-42c56eeb>Appearance</p><div class="appearance-action" data-v-42c56eeb><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-42c56eeb data-v-e81c969b data-v-5d4aee43><span class="check" data-v-5d4aee43><span class="icon" data-v-5d4aee43><!--[--><span class="vpi-sun sun" data-v-e81c969b></span><span class="vpi-moon moon" data-v-e81c969b></span><!--]--></span></span></button></div></div></div><div class="group" data-v-42c56eeb><div class="item social-links" data-v-42c56eeb><div class="VPSocialLinks social-links-list" data-v-42c56eeb data-v-c5f7a4ac><!--[--><a class="VPSocialLink no-icon" href="https://github.com/vuejs/vitepress" aria-label="github" target="_blank" rel="noopener" data-v-c5f7a4ac data-v-acb7c684><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-d662bdbc data-v-716a6ba8><span class="container" data-v-716a6ba8><span class="top" data-v-716a6ba8></span><span class="middle" data-v-716a6ba8></span><span class="bottom" data-v-716a6ba8></span></span></button></div></div></div></div><div class="divider" data-v-d662bdbc><div class="divider-line" data-v-d662bdbc></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-04082acb data-v-3a93fdb1><div class="container" data-v-3a93fdb1><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-3a93fdb1><span class="vpi-align-left menu-icon" data-v-3a93fdb1></span><span class="menu-text" data-v-3a93fdb1>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-3a93fdb1 data-v-9fecb94d><button data-v-9fecb94d>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-04082acb data-v-e9366181><div class="curtain" data-v-e9366181></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-e9366181><span class="visually-hidden" id="sidebar-aria-label" data-v-e9366181> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-999dfcb0><section class="VPSidebarItem level-0 has-active" data-v-999dfcb0 data-v-f88eca86><div class="item" role="button" tabindex="0" data-v-f88eca86><div class="indicator" data-v-f88eca86></div><h2 class="text" data-v-f88eca86>书籍</h2><!----></div><div class="items" data-v-f88eca86><!--[--><div class="VPSidebarItem level-1 is-link" data-v-f88eca86 data-v-f88eca86><div class="item" data-v-f88eca86><div class="indicator" data-v-f88eca86></div><a class="VPLink link link" href="./markdown-examples.html" data-v-f88eca86><!--[--><p class="text" data-v-f88eca86>Markdown Examples</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f88eca86 data-v-f88eca86><div class="item" data-v-f88eca86><div class="indicator" data-v-f88eca86></div><a class="VPLink link link" href="./api-examples.html" data-v-f88eca86><!--[--><p class="text" data-v-f88eca86>Runtime API Examples</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f88eca86 data-v-f88eca86><div class="item" data-v-f88eca86><div class="indicator" data-v-f88eca86></div><a class="VPLink link link" href="./bllm/" data-v-f88eca86><!--[--><p class="text" data-v-f88eca86>欢迎</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f88eca86 data-v-f88eca86><div class="item" data-v-f88eca86><div class="indicator" data-v-f88eca86></div><a class="VPLink link link" href="./bllm/1_understanding_large_language_models.html" data-v-f88eca86><!--[--><p class="text" data-v-f88eca86>理解大型语言模型</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f88eca86 data-v-f88eca86><div class="item" data-v-f88eca86><div class="indicator" data-v-f88eca86></div><a class="VPLink link link" href="./bllm/2_working_with_text_data.html" data-v-f88eca86><!--[--><p class="text" data-v-f88eca86>处理文本数据</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f88eca86 data-v-f88eca86><div class="item" data-v-f88eca86><div class="indicator" data-v-f88eca86></div><a class="VPLink link link" href="./bllm/3_coding_attention_mechanisms.html" data-v-f88eca86><!--[--><p class="text" data-v-f88eca86>编写注意力机制</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f88eca86 data-v-f88eca86><div class="item" data-v-f88eca86><div class="indicator" data-v-f88eca86></div><a class="VPLink link link" href="./bllm/4_implementing_a_gpt_model_from_scratch_to_generate_text.html" data-v-f88eca86><!--[--><p class="text" data-v-f88eca86>从零实现GPT模型生成文本</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f88eca86 data-v-f88eca86><div class="item" data-v-f88eca86><div class="indicator" data-v-f88eca86></div><a class="VPLink link link" href="./bllm/5_pretraining_on_unlabeled_data.html" data-v-f88eca86><!--[--><p class="text" data-v-f88eca86> 在无标签数据上预训练</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f88eca86 data-v-f88eca86><div class="item" data-v-f88eca86><div class="indicator" data-v-f88eca86></div><a class="VPLink link link" href="./bllm/appendix_a_introduction_to_pytorch.html" data-v-f88eca86><!--[--><p class="text" data-v-f88eca86>附录 A. PyTorch简介</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f88eca86 data-v-f88eca86><div class="item" data-v-f88eca86><div class="indicator" data-v-f88eca86></div><a class="VPLink link link" href="./bllm/appendix_b_references_and_further_reading.html" data-v-f88eca86><!--[--><p class="text" data-v-f88eca86>附录 B. 参考文献与进一步阅读</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f88eca86 data-v-f88eca86><div class="item" data-v-f88eca86><div class="indicator" data-v-f88eca86></div><a class="VPLink link link" href="./bllm/appendix_c_exercise_solutions.html" data-v-f88eca86><!--[--><p class="text" data-v-f88eca86>附录 C. 习题解答</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f88eca86 data-v-f88eca86><div class="item" data-v-f88eca86><div class="indicator" data-v-f88eca86></div><a class="VPLink link link" href="./bllm/appendix_d_adding_bells_and_whistles_to_the_training_loop.html" data-v-f88eca86><!--[--><p class="text" data-v-f88eca86>附录 D. 给训练循环添加附加功能</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-999dfcb0><section class="VPSidebarItem level-0" data-v-999dfcb0 data-v-f88eca86><div class="item" role="button" tabindex="0" data-v-f88eca86><div class="indicator" data-v-f88eca86></div><h2 class="text" data-v-f88eca86>课程</h2><!----></div><div class="items" data-v-f88eca86><!--[--><div class="VPSidebarItem level-1 is-link" data-v-f88eca86 data-v-f88eca86><div class="item" data-v-f88eca86><div class="indicator" data-v-f88eca86></div><a class="VPLink link link" href="./course/1.html" data-v-f88eca86><!--[--><p class="text" data-v-f88eca86>课程1</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f88eca86 data-v-f88eca86><div class="item" data-v-f88eca86><div class="indicator" data-v-f88eca86></div><a class="VPLink link link" href="./course/2.html" data-v-f88eca86><!--[--><p class="text" data-v-f88eca86>课程2</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-04082acb data-v-472f5592><div class="VPDoc has-sidebar has-aside" data-v-472f5592 data-v-56ee120b><!--[--><!--]--><div class="container" data-v-56ee120b><div class="aside" data-v-56ee120b><div class="aside-curtain" data-v-56ee120b></div><div class="aside-container" data-v-56ee120b><div class="aside-content" data-v-56ee120b><div class="VPDocAside" data-v-56ee120b data-v-3b40b7c4><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3b40b7c4 data-v-3861d3c5><div class="content" data-v-3861d3c5><div class="outline-marker" data-v-3861d3c5></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-3861d3c5>On this page</div><ul class="VPDocOutlineItem root" data-v-3861d3c5 data-v-6358f6a3><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3b40b7c4></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-56ee120b><div class="content-container" data-v-56ee120b><!--[--><!--]--><main class="main" data-v-56ee120b><div style="position:relative;" class="vp-doc _bllm_5_pretraining_on_unlabeled_data" data-v-56ee120b><div><h1 id="在无标签数据上进行预训练" tabindex="-1">在无标签数据上进行预训练 <a class="header-anchor" href="#在无标签数据上进行预训练" aria-label="Permalink to &quot;在无标签数据上进行预训练&quot;">​</a></h1><h2 id="本章内容" tabindex="-1">本章内容 <a class="header-anchor" href="#本章内容" aria-label="Permalink to &quot;本章内容&quot;">​</a></h2><ul><li>计算训练和验证集损失，以评估 LLM 在训练过程中的文本生成质量</li><li>实现训练函数并对 LLM 进行预训练</li><li>保存和加载模型权重，以继续训练 LLM</li><li>从 OpenAI 加载预训练的权重</li></ul><p>在前几章中，我们实现了数据采样、注意力机制，并编写了 LLM 架构。本章的核心是实现一个训练函数，并对模型进行预训练，如图 5.1 所示。</p><p><strong>图 5.1</strong> 展示了构建 LLM 的三个主要阶段的心智模型：编码 LLM、在通用文本数据集上预训练 LLM，以及在带标签的数据集上微调 LLM。本章重点在于 LLM 的预训练，包括实现训练代码、评估模型性能以及保存和加载模型权重。 <img src="/assets/image-73.v8bAdhJE.png" alt="alt text"> 如图 5.1 所示，我们还将了解基本的模型评估技术，用于在训练过程中衡量生成文本的质量，这是优化 LLM 所需的。此外，我们将讨论如何加载预训练权重，为后续章节中的微调提供一个良好的起点。</p><h4 id="权重参数" tabindex="-1">权重参数 <a class="header-anchor" href="#权重参数" aria-label="Permalink to &quot;权重参数&quot;">​</a></h4><p>在 LLM 和其他深度学习模型的上下文中，<strong>权重</strong>指的是学习过程中会调整的可训练参数。这些权重也称为权重参数，或简而言之为参数。在 PyTorch 等框架中，这些权重通常存储在线性层中，例如我们在第 3 章中用于实现多头注意力模块和第 4 章中用于实现 <code>GPTModel</code> 的线性层。在初始化一个层之后（例如 <code>new_layer = torch.nn.Linear(...)</code>），可以通过 <code>.weight</code> 属性访问其权重，即 <code>new_layer.weight</code>。此外，为了方便起见，PyTorch 允许通过 <code>model.parameters()</code> 方法直接访问模型中所有的可训练参数，包括权重和偏置项。我们将在后续实现模型训练时使用这个方法。</p><h2 id="_5-1-评估生成文本模型" tabindex="-1">5.1 评估生成文本模型 <a class="header-anchor" href="#_5-1-评估生成文本模型" aria-label="Permalink to &quot;5.1 评估生成文本模型&quot;">​</a></h2><p>我们从设置 LLM 开始，以基于上一章的代码生成文本，并在本节中讨论评估生成文本质量的基本方法。本节以及本章剩余内容的结构如图 5.2 所示。</p><p><strong>图 5.2</strong> 提供了本章涵盖主题的概览。我们首先回顾了上一章的文本生成过程，并实现一些基本的模型评估技术，便于在预训练阶段使用。 <img src="/assets/image-74.M_3utqYE.png" alt="alt text"> 正如图 5.2 所示，下一小节将回顾我们在上一章末尾设置的文本生成，然后再深入文本评估，并在接下来的小节中计算训练和验证集的损失。</p><h3 id="_5-1-1-使用-gpt-生成文本" tabindex="-1">5.1.1 使用 GPT 生成文本 <a class="header-anchor" href="#_5-1-1-使用-gpt-生成文本" aria-label="Permalink to &quot;5.1.1 使用 GPT 生成文本&quot;">​</a></h3><p>在本节中，我们设置 LLM 并简要回顾第 4 章实现的文本生成过程。我们从初始化将要在本章中评估和训练的 GPT 模型开始，使用 <code>GPTModel</code> 类和 <code>GPT_CONFIG_124M</code> 字典：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> chapter04 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> GPTModel</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">GPT_CONFIG_124M</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;vocab_size&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">50257</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;context_length&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># A</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;emb_dim&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">768</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;n_heads&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">12</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;n_layers&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">12</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;drop_rate&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># B</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;qkv_bias&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">torch.manual_seed(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">123</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> GPTModel(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">GPT_CONFIG_124M</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model.eval()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div><p>在 <code>GPT_CONFIG_124M</code> 字典中，相比上一章唯一的调整是将上下文长度 (<code>context_length</code>) 减小为 256 个 token。此修改减少了训练模型的计算需求，使得在普通笔记本电脑上进行训练成为可能。</p><p>原始的 GPT-2 模型配置为处理最多 1024 个 token。经过训练后，在本章末尾我们将更新上下文大小设置，并加载预训练权重，使其能够处理 1024-token 上下文长度。</p><p>使用 <code>GPTModel</code> 实例，我们采用上一章介绍的 <code>generate_text_simple</code> 函数，并引入两个便捷函数，<code>text_to_token_ids</code> 和 <code>token_ids_to_text</code>。这两个函数便于在文本和 token 表示之间转换，这也是本章将反复使用的技术。图 5.3 进一步说明了该过程的原理。</p><p><strong>图 5.3</strong> 展示了使用 GPT 模型生成文本的三步过程。首先，分词器将输入文本转换为一系列 token ID（参见第 2 章）。接着，模型接收这些 token ID 并生成相应的 logits（即表示词汇表中每个 token 的概率分布的向量，参见第 4 章）。最后，这些 logits 被转换回 token ID，并由分词器解码为人类可读的文本，完成从文本输入到文本输出的循环。 <img src="/assets/image-75.BOG_Xfsk.png" alt="alt text"> 代码实现如下：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 列表 5.1 文本到 token ID 转换的实用函数</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tiktoken</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> chapter04 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> generate_text_simple</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> text_to_token_ids</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(text, tokenizer):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    encoded </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tokenizer.encode(text, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">allowed_special</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;&lt;|endoftext|&gt;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">})</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    encoded_tensor </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.tensor(encoded).unsqueeze(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 添加批次维度</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> encoded_tensor</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> token_ids_to_text</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(token_ids, tokenizer):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    flat </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> token_ids.squeeze(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 移除批次维度</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tokenizer.decode(flat.tolist())</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">start_context </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;Every effort moves you&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tokenizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tiktoken.get_encoding(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;gpt2&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">token_ids </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> generate_text_simple(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    idx</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">text_to_token_ids(start_context, tokenizer),</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    max_new_tokens</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    context_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">GPT_CONFIG_124M</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;context_length&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Output text:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, token_ids_to_text(token_ids, tokenizer))</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br></div></div><p>使用以上代码，模型生成以下文本：</p><div class="language-plaintext vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">plaintext</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Output text:</span></span>
<span class="line"><span>Every effort moves you rentingetic wasnم refres RexMeCHicular stren</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>从输出可以看出，模型尚未生成连贯的文本，因为它还没有经过训练。要定义文本的“连贯性”或“高质量”，我们需要实现一种数值方法来评估生成内容。这种方法将使我们能够在整个训练过程中监控并提升模型的性能。</p><p>接下来的小节将介绍如何计算生成输出的损失指标。此损失作为训练进展和成功的指示器。此外，在后续的微调 LLM 章节中，我们还将探讨其他评估模型质量的方法。</p><h3 id="_5-1-2-计算文本生成损失" tabindex="-1">5.1.2 计算文本生成损失 <a class="header-anchor" href="#_5-1-2-计算文本生成损失" aria-label="Permalink to &quot;5.1.2 计算文本生成损失&quot;">​</a></h3><p>本节探讨通过计算<strong>文本生成损失</strong>来量化评估生成文本质量的技术。我们将通过实际示例逐步讲解，以便清晰且易于应用，从如何加载数据（第 2 章）和通过 <code>generate_text_simple</code> 函数生成文本（第 4 章）开始复习。</p><p><strong>图 5.4</strong> 展示了从输入文本到 LLM 生成的文本的整体流程，包括五个步骤。 <img src="/assets/image-76.DqaBU-Mj.png" alt="alt text"><strong>图 5.4</strong> 展示了 <code>generate_text_simple</code> 函数的内部生成过程。我们需要执行这些初始步骤，以便在本节后续部分计算生成文本质量的损失。</p><p>图中展示了一个简化的 7-token 词汇表流程以适应页面展示，但我们的 <code>GPTModel</code> 实际使用了 50257 个词汇表单词，因此代码中的 token ID 范围为 0 到 50256，而不是 0 到 6。为简单起见，<strong>图 5.4</strong> 中仅显示了一个文本示例 &quot;every effort moves&quot;。在以下代码示例中，我们将使用两个输入示例作为 GPT 模型的输入：&quot;every effort moves&quot; 和 &quot;I really like&quot;。</p><p>考虑两个已经映射为 token ID 的输入示例，对应图 5.4 中的第 1 步：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">inputs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.tensor([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">16833</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3626</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">6100</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],   </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># [&quot;every effort moves&quot;]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                       [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">40</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1107</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">588</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]])      </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># [&quot;I really like&quot;]</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>与这些输入相对应，<code>targets</code> 包含了我们希望模型生成的目标 token ID：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">targets </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.tensor([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3626</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">6100</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">345</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],   </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># [&quot;effort moves you&quot;]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                        [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">588</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">428</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">11311</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]])  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># [&quot;really like chocolate&quot;]</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>注意，目标是输入序列向后移动一个位置，这一策略在第 2 章的数据加载实现中讨论过。该偏移策略对于教模型预测序列中的下一个 token 至关重要。</p><p>当我们将 <code>inputs</code> 输入到模型中以计算两个输入示例的 logit 向量（每个示例包含三个 token），并应用 softmax 函数将这些 logit 值转换为概率分数时，就完成了图 5.4 中的第 2 步：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.no_grad():  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># A</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    logits </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model(inputs)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    probas </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.softmax(logits, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 词汇表中每个 token 的概率</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(probas.shape)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>生成的概率分数张量的维度为：</p><div class="language-plaintext vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">plaintext</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>torch.Size([2, 3, 50257])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>第一个数字 2 对应于输入示例的数量（即批次大小），第二个数字 3 对应每个输入的 token 数量。最后一个数字 50257 对应词汇表的大小。</p><p>在从 logit 到概率的转换之后（通过 softmax 函数），<code>generate_text_simple</code> 函数将这些概率分数转换回文本，如图 5.4 中的第 3 至第 5 步所示。</p><p>我们可以通过对概率分数应用 <code>argmax</code> 函数来实现第 3 步和第 4 步，从而获得对应的 token ID：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">token_ids </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.argmax(probas, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">keepdim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Token IDs:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, token_ids)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>由于我们有 2 个输入批次，每个批次包含 3 个 token，应用 <code>argmax</code> 函数后得到 2 组输出，每组 3 个预测的 token ID：</p><div class="language-plaintext vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">plaintext</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Token IDs:</span></span>
<span class="line"><span>tensor([[[16657],    # 第一批</span></span>
<span class="line"><span>         [  339],</span></span>
<span class="line"><span>         [42826]],</span></span>
<span class="line"><span>        [[49906],    # 第二批</span></span>
<span class="line"><span>         [29669],</span></span>
<span class="line"><span>         [41751]]])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>最后，第 5 步将 token ID 转换回文本：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Targets batch 1: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">token_ids_to_text(targets[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], tokenizer)</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Outputs batch 1: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">token_ids_to_text(token_ids[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].flatten(), tokenizer)</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>解码这些 token 后，我们发现输出 token 与目标 token 相差很大，因为模型还没有经过训练：</p><div class="language-plaintext vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">plaintext</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Targets batch 1: effort moves you</span></span>
<span class="line"><span>Outputs batch 1: Armed heNetflix</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>模型生成了与目标文本不同的随机文本，因为它尚未经过训练。接下来，我们将介绍如何通过计算所谓的<strong>损失</strong>来数值化评估模型生成文本的表现，如图 5.4 所示。这不仅有助于衡量生成文本的质量，也是我们稍后用以更新模型权重、改进生成文本的训练函数的构建模块。</p><p><strong>图 5.5</strong> 展示了文本评估函数的实现步骤。在下一节中，我们会将此评估函数应用于整个训练数据集。 <img src="/assets/image-77.CdxAGiaH.png" alt="alt text"> 在模型训练中，目标是增加正确目标 token ID 对应位置的 softmax 概率，如图 5.6 所示。该 softmax 概率也用于我们在本节中实现的评估指标：目标位置概率越高越好。</p><p>记住，<strong>图 5.6</strong> 显示了一个仅包含 7 个 token 的词汇表的 softmax 概率，目的是适应图示。因此起始随机值大约为 1/7，即 0.14。而我们 GPT-2 模型的词汇量为 50257，因此大多数初始概率会在 1/50257 附近，即约 0.00002。 <img src="/assets/image-78.BI_qgc17.png" alt="alt text"> 对于两个输入文本，我们可以通过以下代码打印目标 token 的初始 softmax 概率分数：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">text_idx </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">target_probas_1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> probas[text_idx, [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], targets[text_idx]]</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Text 1:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, target_probas_1)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">text_idx </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">target_probas_2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> probas[text_idx, [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], targets[text_idx]]</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Text 2:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, target_probas_2)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>每个批次的 3 个目标 token ID 概率如下：</p><div class="language-plaintext vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">plaintext</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])</span></span>
<span class="line"><span>Text 2: tensor([3.9836e-05, 1.6783e-05, 4.7559e-06])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>LLM 训练的目标是将这些值尽量提高，使其接近 1，从而确保模型始终选择目标 token——即句子中的下一个单词——作为生成的下一个 token。</p><h4 id="反向传播" tabindex="-1">反向传播 <a class="header-anchor" href="#反向传播" aria-label="Permalink to &quot;反向传播&quot;">​</a></h4><p>我们如何最大化这些目标 token 对应的 softmax 概率？方法是通过更新模型的权重，使得模型为期望的 token ID 输出更高的值。这种权重更新通过一种称为<strong>反向传播</strong>的过程实现，这是训练深度神经网络的标准技术（详情见附录 A 的 A.3 到 A.7 节）。</p><p>反向传播需要一个<strong>损失函数</strong>，该函数计算模型预测输出（即目标 token ID 对应的概率）与实际期望输出的差异。这个损失函数衡量模型预测偏离目标值的程度。</p><p>在本节的其余部分，我们将计算两个示例批次（<code>target_probas_1</code> 和 <code>target_probas_2</code>）概率分数的损失。主要步骤见图 5.7。</p><p><strong>图 5.7</strong> 展示了计算损失的几个步骤。第 1 至第 3 步计算目标张量对应的 token 概率。这些概率在第 4 至第 6 步中通过对数变换并求平均值。 <img src="/assets/image-79.bYyXUDy9.png" alt="alt text"> 我们已经通过第 1 至第 3 步得到 <code>target_probas_1</code> 和 <code>target_probas_2</code>，接下来是第 4 步，对概率分数应用对数：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">log_probas </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.log(torch.cat((target_probas_1, target_probas_2)))</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(log_probas)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>结果如下：</p><div class="language-plaintext vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">plaintext</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>tensor([ -9.5042, -10.3796, -11.3677, -10.1308, -10.9951, -12.2561])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>处理概率分数的对数在数学优化中更易操作。这一主题超出本书范围，但可参考附录 B 提到的讲座以了解更多。</p><p>接下来，我们计算这些对数概率的平均值（图 5.7 中的第 5 步）：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">avg_log_probas </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.mean(log_probas)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(avg_log_probas)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>结果如下：</p><div class="language-plaintext vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">plaintext</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>tensor(-10.7722)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>模型训练的目标是使平均对数概率尽量接近 0，稍后将在 5.2 节实现的训练过程中更新模型权重实现该目标。</p><p>在深度学习中，通常的做法不是将平均对数概率提升到 0，而是将负的平均对数概率降低到 0。负的平均对数概率等于平均对数概率乘以 -1，对应图 5.7 中的第 6 步：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">neg_avg_log_probas </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> avg_log_probas </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(neg_avg_log_probas)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>这将结果 <code>tensor(-10.7722)</code> 转为 <code>10.7722</code>，即<strong>交叉熵损失</strong>。</p><p>PyTorch 提供了便捷的 <code>cross_entropy</code> 函数，可为我们完成图 5.7 中的所有 6 步。</p><h4 id="交叉熵损失" tabindex="-1">交叉熵损失 <a class="header-anchor" href="#交叉熵损失" aria-label="Permalink to &quot;交叉熵损失&quot;">​</a></h4><p>本质上，<strong>交叉熵损失</strong>是机器学习和深度学习中的一种常用度量，衡量两个概率分布之间的差异——通常为标签的真实分布（这里是数据集中的 token）和模型预测分布（例如，LLM 生成的 token 概率分布）。</p><p>在 PyTorch 中，<code>cross_entropy</code> 函数计算离散结果的损失，与目标 token 给定的模型生成的 token 概率的负平均对数概率相似，因此在实践中交叉熵和负平均对数概率常常可互换使用。</p><p>在应用 <code>cross_entropy</code> 函数前，让我们回顾 logits 和 targets 张量的形状：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Logits shape:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, logits.shape)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Targets shape:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, targets.shape)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>输出形状如下：</p><div class="language-plaintext vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">plaintext</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Logits shape: torch.Size([2, 3, 50257])</span></span>
<span class="line"><span>Targets shape: torch.Size([2, 3])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>logits 张量有三维：批次大小、token 数量和词汇表大小。而 targets 张量有二维：批次大小和 token 数量。</p><p>为了使 <code>cross_entropy</code> 函数在 PyTorch 中使用，我们需要在批次维度上展平这些张量：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">logits_flat </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> logits.flatten(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">targets_flat </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> targets.flatten()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Flattened logits:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, logits_flat.shape)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Flattened targets:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, targets_flat.shape)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>生成的张量维度为：</p><div class="language-plaintext vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">plaintext</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Flattened logits: torch.Size([6, 50257])</span></span>
<span class="line"><span>Flattened targets: torch.Size([6])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>记住，targets 是我们希望 LLM 生成的 token ID，logits 则是进入 softmax 函数前的未缩放模型输出。</p><p>之前，我们应用 softmax 函数，选择目标 ID 对应的概率分数，并计算负平均对数概率。PyTorch 的 <code>cross_entropy</code> 函数将为我们完成这些步骤：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn.functional.cross_entropy(logits_flat, targets_flat)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(loss)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>生成的损失与之前手动应用图 5.7 中各步骤的结果一致：</p><div class="language-plaintext vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">plaintext</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>tensor(10.7722)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><h4 id="困惑度" tabindex="-1">困惑度 <a class="header-anchor" href="#困惑度" aria-label="Permalink to &quot;困惑度&quot;">​</a></h4><p><strong>困惑度</strong>是一种常用于语言建模任务的度量，与交叉熵损失一起使用，可更直观地了解模型在预测序列下一个 token 时的不确定性。</p><p>困惑度衡量模型预测的概率分布与数据集实际分布的匹配程度。与损失类似，较低的困惑度表示模型预测更接近实际分布。</p><p>困惑度可通过 <code>torch.exp(loss)</code> 计算。应用到先前计算的损失时，返回 <code>tensor(47678.8633)</code>。</p><p>困惑度比原始损失值更具解释性，因为它表示模型在每一步中不确定的有效词汇大小。在给定示例中，这相当于模型在 47678 个词或 token 中不确定生成哪个作为下一个 token。</p><p>本节中，我们计算了两个小文本输入的损失用于说明。在下一节中，我们将把损失计算应用于整个训练和验证集。</p><h3 id="_5-1-3-计算训练集和验证集的损失" tabindex="-1">5.1.3 计算训练集和验证集的损失 <a class="header-anchor" href="#_5-1-3-计算训练集和验证集的损失" aria-label="Permalink to &quot;5.1.3 计算训练集和验证集的损失&quot;">​</a></h3><p>本节首先准备训练和验证数据集，随后将计算训练和验证集的交叉熵损失，这在模型训练过程中是非常重要的一步。<strong>图 5.8</strong> 展示了在前一节计算交叉熵损失之后，将该损失计算应用于整个文本数据集的过程。 <img src="/assets/image-80.DMhVGxOk.png" alt="alt text"> 为了计算训练集和验证集上的损失，我们使用了一个非常小的文本数据集，即第 2 章中使用的 Edith Wharton 的短篇小说《The Verdict》。选择公共领域的文本可以避免使用权相关问题。此外，我们选择较小的数据集是为了便于在普通笔记本电脑上快速运行代码示例，即使没有高端 GPU 也可以轻松执行，非常适合学习用途。</p><p>对于感兴趣的读者，书中的附加代码还提供了更大规模的数据集准备方法，可以使用来自 Project Gutenberg 的超过 60,000 本公共领域书籍训练 LLM（见附录 D 了解详情）。</p><h4 id="预训练-llm-的成本" tabindex="-1">预训练 LLM 的成本 <a class="header-anchor" href="#预训练-llm-的成本" aria-label="Permalink to &quot;预训练 LLM 的成本&quot;">​</a></h4><p>将项目规模放在实际背景中，可以参考训练一个相对流行的开源 LLM（例如 70 亿参数的 Llama 2 模型）所需的资源。该模型训练了 2 万亿 tokens，使用了昂贵的 A100 GPU 共计 184,320 小时。目前，AWS 上的 8xA100 云服务器每小时大约 $30，训练此类 LLM 的粗略成本约为 $690,000。</p><p>以下代码加载了第 2 章中使用的短篇小说《The Verdict》：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">file_path </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;the-verdict.txt&quot;</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> open</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(file_path, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;r&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">encoding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;utf-8&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> file</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    text_data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> file</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.read()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>加载数据集后，我们可以检查字符和 token 数量：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">total_characters </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(text_data)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">total_tokens </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(tokenizer.encode(text_data))</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Characters:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, total_characters)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Tokens:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, total_tokens)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>输出如下：</p><div class="language-plaintext vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">plaintext</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Characters: 20479</span></span>
<span class="line"><span>Tokens: 5145</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>虽然只有 5145 个 tokens，可能看起来过小而无法训练一个 LLM，但正如前述，这主要用于教育目的，因此我们可以在几分钟内完成代码运行，而不需数周。此外，在本章结束时，我们将从 OpenAI 加载预训练权重用于 <code>GPTModel</code>。</p><p>接下来，我们将数据集分为训练集和验证集，并使用第 2 章的 <code>data loader</code> 准备 LLM 训练的批次。如<strong>图 5.9</strong> 所示，数据准备过程包括将输入文本划分为训练和验证集，然后将文本 token 化并分割为指定长度的文本块（图中为 6），最后对文本块行进行随机化并组织成批次供模型训练使用。 <img src="/assets/image-81.CAE0UkBf.png" alt="alt text"> 在实际的 <code>data loader</code> 实现中，<code>max_length</code> 设置为 LLM 支持的 256-token 长度，以确保模型在训练时可以看到更长的文本。</p><h4 id="使用可变长度进行训练" tabindex="-1">使用可变长度进行训练 <a class="header-anchor" href="#使用可变长度进行训练" aria-label="Permalink to &quot;使用可变长度进行训练&quot;">​</a></h4><p>我们用相似大小的文本块来训练模型，这样做简单且高效。然而，在实际中，使用可变长度输入训练 LLM 有助于模型在不同类型输入上更好地泛化。</p><p>要实现图 5.9 中的分割和加载数据，我们首先定义 <code>train_ratio</code> 使用 90% 数据用于训练，剩余 10% 用于模型训练期间的验证评估：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">train_ratio </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.90</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">split_idx </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(train_ratio </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(text_data))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">train_data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> text_data[:split_idx]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">val_data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> text_data[split_idx:]</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>使用 <code>train_data</code> 和 <code>val_data</code> 子集，我们可以重用第 2 章的 <code>create_dataloader_v1</code> 代码来创建数据加载器：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> chapter02 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> create_dataloader_v1</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">torch.manual_seed(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">123</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">train_loader </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> create_dataloader_v1(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    train_data,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    batch_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    max_length</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">GPT_CONFIG_124M</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;context_length&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    stride</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">GPT_CONFIG_124M</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;context_length&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    drop_last</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    shuffle</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">val_loader </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> create_dataloader_v1(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    val_data,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    batch_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    max_length</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">GPT_CONFIG_124M</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;context_length&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    stride</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">GPT_CONFIG_124M</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;context_length&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    drop_last</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    shuffle</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><p>以上代码中使用了相对较小的批次大小，以减少计算资源需求，因为我们使用了非常小的数据集。实际中，训练 LLM 的批次大小达到 1024 或更大很常见。</p><p>作为可选检查，我们可以迭代数据加载器以确保它们正确创建：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Train loader:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x, y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> train_loader:</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x.shape, y.shape)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">Validation loader:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x, y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> val_loader:</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x.shape, y.shape)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>输出如下：</p><div class="language-plaintext vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">plaintext</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Train loader:</span></span>
<span class="line"><span>torch.Size([2, 256]) torch.Size([2, 256])</span></span>
<span class="line"><span>torch.Size([2, 256]) torch.Size([2, 256])</span></span>
<span class="line"><span>...</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Validation loader:</span></span>
<span class="line"><span>torch.Size([2, 256]) torch.Size([2, 256])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>如代码输出所示，我们有 9 个训练集批次，每个批次包含 2 个样本和 256 个 token。由于仅将 10% 的数据用于验证，因此仅有 1 个验证批次。</p><p>接下来，我们实现一个实用函数，用于计算训练和验证加载器返回批次的交叉熵损失：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> calc_loss_batch</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(input_batch, target_batch, model, device):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    input_batch, target_batch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> input_batch.to(device), target_batch.to(device)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># A</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    logits </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model(input_batch)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn.functional.cross_entropy(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        logits.flatten(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), target_batch.flatten()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> loss</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>现在我们可以使用 <code>calc_loss_batch</code> 函数（计算单个批次的损失）来实现 <code>calc_loss_loader</code> 函数，以计算给定数据加载器上所有批次的损失：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> calc_loss_loader</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(data_loader, model, device, num_batches</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    total_loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> num_batches </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        num_batches </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(data_loader)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># A</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    else</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        num_batches </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> min</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(num_batches, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(data_loader))  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># B</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i, (input_batch, target_batch) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> enumerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(data_loader):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> num_batches:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> calc_loss_batch(input_batch, target_batch, model, device)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            total_loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> loss.item()  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># C</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        else</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">            break</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> total_loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> num_batches  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># D</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><p>默认情况下，<code>calc_loss_loader</code> 函数遍历给定数据加载器中的所有批次，累加损失在 <code>total_loss</code> 变量中，最后计算并平均损失。如果在 <code>num_batches</code> 参数中指定较小的批次数，也可以加速模型训练中的评估。</p><p>现在我们可以应用 <code>calc_loss_loader</code> 函数到训练和验证集加载器：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">device </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.device(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;cuda&quot;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.cuda.is_available() </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">else</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;cpu&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># A</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model.to(device)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">train_loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> calc_loss_loader(train_loader, model, device)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># B</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">val_loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> calc_loss_loader(val_loader, model, device)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Training loss:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, train_loss)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Validation loss:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, val_loss)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>结果损失值如下：</p><div class="language-plaintext vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">plaintext</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Training loss: 10.98758347829183</span></span>
<span class="line"><span>Validation loss: 10.98110580444336</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>由于模型尚未训练，损失值相对较高。作为对比，如果模型能够学习生成训练集和验证集中的下一个 token，损失将接近 0。</p><p>现在，我们已经有方法评估生成文本的质量。接下来一节，我们将训练 LLM 减少损失，使其生成更优质的文本，如<strong>图 5.10</strong> 所示。 <img src="/assets/image-82.ClWNpREe.png" alt="alt text"> 如图所示，下一节将聚焦于 LLM 的预训练。</p><h2 id="_5-2-训练大语言模型" tabindex="-1">5.2 训练大语言模型 <a class="header-anchor" href="#_5-2-训练大语言模型" aria-label="Permalink to &quot;5.2 训练大语言模型&quot;">​</a></h2><p>在本节中，我们将实现训练大语言模型（LLM）<code>GPTModel</code>的代码。为了使代码简洁易懂，我们将采用一个简单的训练循环，如图5.11所示。不过，有兴趣的读者可以在附录D《为训练循环添加功能》中了解更高级的技术，如学习率预热、余弦退火和梯度裁剪等。</p><p>图5.11展示了一个典型的PyTorch深度神经网络训练循环，包含多个步骤，遍历训练集中的批次并进行多轮迭代。在每次循环中，我们计算每个训练集批次的损失，以确定损失的梯度，并使用这些梯度来更新模型权重，从而最小化训练集损失。 <img src="/assets/image-83.4lQ4guwR.png" alt="alt text"> 图5.11中显示的流程图描述了用于训练LLM的典型PyTorch神经网络训练流程，共八个步骤，开始于遍历每个训练轮次、处理批次、重置和计算梯度、更新权重，最后是监控步骤，如打印损失和生成文本样本。如果您对使用PyTorch训练深度神经网络不熟悉，可以参考附录A中的A.5到A.8节。</p><p>代码中，我们可以通过以下<code>train_model_simple</code>函数实现这一训练流程：</p><p><strong>代码清单5.3</strong> 用于预训练LLM的主函数</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> train_model_simple</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(model, train_loader, val_loader, optimizer, device, num_epochs,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                       eval_freq, eval_iter, start_context):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    train_losses, val_losses, track_tokens_seen </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [], [], []  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#A</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    tokens_seen, global_step </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> epoch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(num_epochs):  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#B</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        model.train()</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> input_batch, target_batch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> train_loader:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            optimizer.zero_grad()  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#C</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> calc_loss_batch(input_batch, target_batch, model, device)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            loss.backward()  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#D</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            optimizer.step()  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#E</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            tokens_seen </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> input_batch.numel()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            global_step </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">            if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> global_step </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">%</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> eval_freq </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#F</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                train_loss, val_loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> evaluate_model(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                    model, train_loader, val_loader, device, eval_iter)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                train_losses.append(train_loss)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                val_losses.append(val_loss)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                track_tokens_seen.append(tokens_seen)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">                print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Ep </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">epoch</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> (Step </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">global_step</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:06d</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">): &quot;</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">                      f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Train loss </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">train_loss</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:.3f</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">, Val loss </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">val_loss</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:.3f</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                generate_and_print_sample(  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#G</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                    model, train_loader.dataset.tokenizer, device, start_context</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                )</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> train_losses, val_losses, track_tokens_seen</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br></div></div><p>请注意，我们刚刚创建的<code>train_model_simple</code>函数使用了两个尚未定义的函数：<code>evaluate_model</code>和<code>generate_and_print_sample</code>。</p><p><code>evaluate_model</code>函数对应图5.11中的第7步。它在每次模型更新后打印训练集和验证集的损失，使我们能够评估训练是否使模型有所改进。</p><p>具体来说，<code>evaluate_model</code>函数计算训练集和验证集的损失，并确保在计算损失时模型处于评估模式（禁用梯度跟踪和dropout）：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> evaluate_model</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(model, train_loader, val_loader, device, eval_iter):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model.eval()  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#A</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.no_grad():  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#B</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        train_loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> calc_loss_loader(train_loader, model, device, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">num_batches</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">eval_iter)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        val_loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> calc_loss_loader(val_loader, model, device, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">num_batches</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">eval_iter)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model.train()</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> train_loss, val_loss</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>与<code>evaluate_model</code>类似，<code>generate_and_print_sample</code>函数是一个辅助函数，用于跟踪模型在训练过程中的改进情况。特别是，<code>generate_and_print_sample</code>函数接收一个文本片段（<code>start_context</code>）作为输入，将其转换为令牌ID，并将其输入到LLM中以生成一个文本样本，使用我们之前定义的<code>generate_text_simple</code>函数：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> generate_and_print_sample</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(model, tokenizer, device, start_context):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model.eval()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    context_size </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.pos_emb.weight.shape[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    encoded </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> text_to_token_ids(start_context, tokenizer).to(device)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.no_grad():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        token_ids </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> generate_text_simple(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">            model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">idx</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">encoded,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">            max_new_tokens</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">50</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">context_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">context_size</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        )</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    decoded_text </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> token_ids_to_text(token_ids, tokenizer)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(decoded_text.replace(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot; &quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 紧凑的打印格式</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model.train()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p><code>evaluate_model</code>函数为我们提供了模型训练进展的数值估计，而<code>generate_and_print_sample</code>文本函数则生成了模型的具体文本示例，用于评估其训练能力。</p><p><strong>AdamW优化器</strong></p><p>Adam优化器是深度神经网络训练的常见选择。然而，在我们的训练循环中，我们选择使用AdamW优化器。AdamW是Adam的一个变体，改进了权重衰减的方法，旨在通过惩罚较大的权重来最小化模型复杂度并防止过拟合。这种调整使AdamW实现了更有效的正则化和更好的泛化，因此经常用于训练LLM。</p><p>让我们使用AdamW优化器和之前定义的<code>train_model_simple</code>函数训练一个GPT模型实例10个轮次，看看效果。</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">torch.manual_seed(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">123</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> GPTModel(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">GPT_CONFIG_124M</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model.to(device)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">optimizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.optim.AdamW(model.parameters(), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">lr</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0004</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">weight_decay</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#A</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">num_epochs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 10</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">train_losses, val_losses, tokens_seen </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> train_model_simple(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model, train_loader, val_loader, optimizer, device,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    num_epochs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">num_epochs, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">eval_freq</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">eval_iter</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    start_context</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Every effort moves you&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><p>执行<code>train_model_simple</code>函数将启动训练过程，在MacBook Air或类似笔记本电脑上大约需要5分钟。训练过程中打印的输出如下：</p><div class="language-vbnet vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">vbnet</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Ep 1 (Step 000000): Train loss 9.781, Val loss 9.933</span></span>
<span class="line"><span>Ep 1 (Step 000005): Train loss 8.111, Val loss 8.339</span></span>
<span class="line"><span>Every effort moves you,,,,,,,,,,,,.</span></span>
<span class="line"><span>Ep 2 (Step 000010): Train loss 6.661, Val loss 7.048</span></span>
<span class="line"><span>Ep 2 (Step 000015): Train loss 5.961, Val loss 6.616</span></span>
<span class="line"><span>Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,</span></span>
<span class="line"><span>...</span></span>
<span class="line"><span>Ep 9 (Step 000080): Train loss 0.541, Val loss 6.393</span></span>
<span class="line"><span>Every effort moves you?&quot; &quot;Yes--quite insensible to the irony. She wanted him vindicated--and by me!&quot; He laughed again, and threw back the window-curtains, I had the donkey. &quot;There were days when I</span></span>
<span class="line"><span>Ep 10 (Step 000085): Train loss 0.391, Val loss 6.452</span></span>
<span class="line"><span>Every effort moves you know,&quot; was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p>从训练过程中打印的结果可以看出，训练损失大幅下降，从9.558收敛到0.762，模型的语言能力提高了很多。起初，模型只能在起始内容后添加逗号（如<code>&quot;Every effort moves you,,,,,,,,,,,,&quot;</code>）或重复“and”一词。到训练结束时，它已能生成语法正确的文本。</p><p>与训练集损失类似，我们可以看到验证集损失从高值（9.856）开始，并在训练过程中逐渐下降。然而，它从未接近训练集损失，并在第10轮后保持在6.372。</p><p>在更详细地讨论验证集损失之前，让我们绘制一个简单的图表，将训练集和验证集的损失并列显示：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> matplotlib.pyplot </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> plt</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> plot_losses</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(epochs_seen, tokens_seen, train_losses, val_losses):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    fig, ax1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> plt.subplots(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">figsize</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ax1.plot(epochs_seen, train_losses, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">label</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Training loss&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ax1.plot(epochs_seen, val_losses, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">linestyle</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;-.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">label</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Validation loss&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ax1.set_xlabel(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Epochs&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ax1.set_ylabel(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Loss&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ax1.legend(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">loc</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;upper right&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ax2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ax1.twiny()  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#A</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ax2.plot(tokens_seen, train_losses, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">alpha</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#B</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ax2.set_xlabel(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Tokens seen&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    fig.tight_layout()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">epochs_tensor </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.linspace(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, num_epochs, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(train_losses))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div><p>生成的训练和验证损失图如图5.12所示。 <img src="/assets/image-84.DEKz8yRu.png" alt="alt text"> 图5.12显示了在训练开始时，训练集和验证集的损失均迅速下降，这是模型学习的标志。然而，训练集损失在第二轮之后继续下降，而验证集损失则停滞不前。这表明模型仍在学习，但在第二轮之后对训练集的拟合过度。</p><p>这种记忆现象是意料之中的，因为我们使用的训练数据集非常小，并对模型进行了多轮训练。通常情况下，模型只在更大的数据集上训练一轮。如前所述，有兴趣的读者可以尝试使用Project Gutenberg的60,000本公共领域书籍训练模型，届时不会发生这种过拟合现象；详情见附录B。</p><p>在接下来的章节中（如图5.13所示），我们将探讨LLM所采用的采样方法，以减少记忆效应，从而生成更具新意的文本。 <img src="/assets/image-85.amA9chp6.png" alt="alt text"> 如图5.13所示，下一节将介绍生成策略，以降低LLM对训练数据的记忆效应，提高LLM生成文本的原创性。</p><h2 id="_5-3-解码策略以控制随机性" tabindex="-1">5.3 解码策略以控制随机性 <a class="header-anchor" href="#_5-3-解码策略以控制随机性" aria-label="Permalink to &quot;5.3 解码策略以控制随机性&quot;">​</a></h2><p>在本节中，我们将介绍生成文本的策略（也称为解码策略），以生成更具原创性的文本。首先，我们简要回顾上一章中使用的<code>generate_text_simple</code>函数，我们在本章中调用了它，放置在<code>generate_and_print_sample</code>函数内部。接下来，我们将介绍两种技术：温度缩放和Top-k采样，以改进该函数。</p><p>我们首先将模型从GPU传回CPU，因为对于相对较小的模型来说，推理过程并不需要GPU。同时，在训练完成后，我们将模型置于评估模式以关闭随机成分，如dropout：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model.to(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;cpu&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model.eval()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>接下来，我们将GPT模型实例（<code>model</code>）插入到<code>generate_text_simple</code>函数中，该函数使用LLM一次生成一个token：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tokenizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tiktoken.get_encoding(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;gpt2&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">token_ids </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> generate_text_simple(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    idx</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">text_to_token_ids(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Every effort moves you&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, tokenizer),</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    max_new_tokens</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">25</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    context_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">GPT_CONFIG_124M</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;context_length&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Output text:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, token_ids_to_text(token_ids, tokenizer))</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>生成的文本如下：</p><div class="language-arduino vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">arduino</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Output text:</span></span>
<span class="line"><span>Every effort moves you know,&quot; was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed lun</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>如前文5.1.2节所述，每个生成步骤选择的token对应于词汇表中具有最高概率得分的token。</p><p>这意味着，即使多次运行上述<code>generate_text_simple</code>函数并使用相同的起始内容（“Every effort moves you”），LLM也将始终生成相同的输出。</p><p>以下小节将介绍两个概念，以控制生成文本的随机性和多样性：温度缩放和Top-k采样。</p><h3 id="_5-3-1-温度缩放" tabindex="-1">5.3.1 温度缩放 <a class="header-anchor" href="#_5-3-1-温度缩放" aria-label="Permalink to &quot;5.3.1 温度缩放&quot;">​</a></h3><p>本节介绍温度缩放，这是一种为下一个token生成任务添加概率选择过程的技术。</p><p>在之前的<code>generate_text_simple</code>函数中，我们始终通过<code>torch.argmax</code>选择概率最高的token作为下一个token，这种方式称为贪婪解码。为了生成更多样化的文本，我们可以用一个从概率分布中采样的函数来替换<code>argmax</code>（在这里，概率分布是LLM在每个token生成步骤中为每个词汇生成的概率得分）。</p><p>为了通过具体示例说明概率采样过程，我们用一个非常小的词汇表来讨论下一个token生成过程：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">vocab </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;closer&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;every&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;effort&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;forward&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;inches&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;moves&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;pizza&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">6</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;toward&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">7</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;you&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">8</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">inverse_vocab </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {v: k </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> k, v </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> vocab.items()}</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>接下来，假设LLM接收起始内容“every effort moves you”，并生成以下的下一个token的logits值：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">next_token_logits </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.tensor(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4.51</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.89</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.90</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">6.75</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.63</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.62</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.89</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">6.28</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.79</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>在之前的章节中讨论过，在<code>generate_text_simple</code>中，我们通过softmax函数将logits转换为概率，再通过<code>argmax</code>函数找到对应的token ID，然后可以通过逆向词汇表将其映射回文本：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">probas </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.softmax(next_token_logits, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">next_token_id </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.argmax(probas).item()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(inverse_vocab[next_token_id])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>由于最大logit值位于第四个位置（索引位置为3，因为Python使用0索引），生成的单词是“forward”。</p><p>为了实现概率采样过程，我们现在可以用PyTorch中的<code>multinomial</code>函数替换<code>argmax</code>：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">torch.manual_seed(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">123</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">next_token_id </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.multinomial(probas, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">num_samples</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).item()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(inverse_vocab[next_token_id])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>输出依然是“forward”。这是为什么呢？<code>multinomial</code>函数根据每个token的概率得分进行采样。换句话说，“forward”仍然是最可能的token，并且在大多数情况下会被<code>multinomial</code>选中，但不是总是如此。为了说明这一点，我们实现一个函数，重复此采样1000次：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> print_sampled_tokens</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(probas):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    torch.manual_seed(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">123</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    sample </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [torch.multinomial(probas, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">num_samples</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).item() </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1_000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    sampled_ids </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.bincount(torch.tensor(sample))</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i, freq </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> enumerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(sampled_ids):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">freq</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> x </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">inverse_vocab[i]</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">print_sampled_tokens(probas)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>采样结果如下：</p><div class="language-sql vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">sql</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">73</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x closer</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x every</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x effort</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">582</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x forward</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x inches</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x moves</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x pizza</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">343</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x toward</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>如结果所示，单词“forward”在大多数情况下被采样（1000次中有582次），但其他token如“closer”、“inches”和“toward”也有一定概率被采样。这意味着，如果在<code>generate_and_print_sample</code>函数中用<code>multinomial</code>函数替换<code>argmax</code>函数，LLM有时会生成“every effort moves you toward”、“every effort moves you inches”和“every effort moves you closer”等不同的文本，而不仅是“every effort moves you forward”。</p><p>我们可以通过一种称为温度缩放的概念进一步控制分布和选择过程，温度缩放实际上是将logits除以一个大于0的数：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> softmax_with_temperature</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(logits, temperature):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    scaled_logits </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> logits </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> temperature</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.softmax(scaled_logits, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>温度大于1时，token概率分布会更接近于均匀分布；温度小于1时，分布会更尖锐（分布的峰值更明显）。我们通过绘制原始概率及不同温度值缩放后的概率来说明这一点：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">temperatures </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 原始、较高和较低的温度</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">scaled_probas </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [softmax_with_temperature(next_token_logits, T) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> T </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> temperatures]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.arange(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(vocab))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">bar_width </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.15</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">fig, ax </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> plt.subplots(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">figsize</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i, T </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> enumerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(temperatures):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    rects </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ax.bar(x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> bar_width, scaled_probas[i],</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                   bar_width, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">label</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Temperature = </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">T</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ax.set_ylabel(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Probability&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ax.set_xticks(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ax.set_xticklabels(vocab.keys(), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">rotation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">90</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ax.legend()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">plt.tight_layout()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">plt.show()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><p><img src="/assets/image-86.DQb2NKZN.png" alt="alt text"> 生成的图如图5.14所示。</p><p>图5.14中显示，温度为1时表示每个token的概率分数未进行缩放。将温度降低至0.1使分布更加尖锐，因此最可能的token（此处为“forward”）的概率得分会更高。相反，将温度升至5使分布更均匀。</p><p>温度为1时，将logits除以1，然后将其传递给softmax函数来计算概率分数。换句话说，使用温度1相当于不进行任何温度缩放。在这种情况下，通过PyTorch中的<code>multinomial</code>采样函数，token的选择概率等于原始softmax概率分数。例如，对于温度设置1，图5.14显示“forward”对应的token被选择的概率约为60%。</p><p>此外，图5.14显示，使用非常小的温度（如0.1）将导致分布更加尖锐，从而使<code>multinomial</code>函数的行为接近<code>argmax</code>，几乎100%地选择最可能的token（此处为“forward”）。相反，温度5的分布更均匀，其他token更频繁地被选择，这可以为生成的文本添加更多变化，但也更容易导致无意义的文本。例如，使用温度5时，“every effort moves you pizza”会以约4%的概率生成。</p><h4 id="练习5-1" tabindex="-1">练习5.1 <a class="header-anchor" href="#练习5-1" aria-label="Permalink to &quot;练习5.1&quot;">​</a></h4><p>使用<code>print_sampled_tokens</code>函数打印温度图5.13所示的softmax概率缩放后的采样频率。每种情况下“pizza”这个单词被采样的频率是多少？你能想到一种更快速且更准确的方法来确定“pizza”被采样的频率吗？</p><h3 id="_5-3-2-top-k采样" tabindex="-1">5.3.2 Top-k采样 <a class="header-anchor" href="#_5-3-2-top-k采样" aria-label="Permalink to &quot;5.3.2 Top-k采样&quot;">​</a></h3><p>在上一节中，我们实现了一种结合温度缩放的概率采样方法，以增加输出的多样性。我们看到，较高的温度值会使下一个token的概率分布更接近均匀分布，从而减少模型重复选择最可能token的概率，这使得生成过程可以探索那些概率较低但潜在更有趣和富有创造性的路径。然而，这种方法的一个缺点是，有时会生成语法不正确或完全无意义的内容，比如“every effort moves you pizza”。</p><p>在本节中，我们引入另一种称为Top-k采样的概念，将其与概率采样和温度缩放相结合，可以进一步改善文本生成效果。</p><p>在Top-k采样中，我们将采样限制在概率最高的前k个token内，排除所有其他token，并将它们的概率分数设为无穷小（如图5.15所示）。 <img src="/assets/image-87.C9xtWK4a.png" alt="alt text"> 图5.15中展示了当k=3时使用Top-k采样的过程。我们仅关注与最高logits值关联的3个token，并在应用softmax函数之前将所有其他token的值设为负无穷（-inf）。这会生成一个概率分布，其中非Top-k token的概率值为0。</p><p>图5.15中的方法将所有未选择的logits值替换为负无穷值（-inf），因此在计算softmax值时，非Top-k token的概率为0，而剩余token的概率之和为1。（细心的读者可能会记得我们在3.5.1节的因果注意力掩码模块中也使用过这种掩码技巧。）</p><p>在代码中，我们可以按照图5.15所示实现Top-k过程，首先选择logits值最高的token：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">top_k </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 3</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">top_logits, top_pos </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.topk(next_token_logits, top_k)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Top logits:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, top_logits)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Top positions:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, top_pos)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>前3个token的logits值和token ID（按降序排列）如下所示：</p><div class="language-css vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">css</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Top logits: tensor([6.7500, 6.2800, 4.5100])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Top positions: tensor([3, 7, 0])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>接着，我们使用PyTorch的<code>where</code>函数，将Top-k选择范围之外的token的logit值设为负无穷（-inf）：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">new_logits </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.where(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    condition</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">next_token_logits </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> top_logits[</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#A</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    input</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">torch.tensor(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">float</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;-inf&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)),  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#B</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    other</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">next_token_logits  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#C</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(new_logits)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>在这个9个token的词汇表中，下一token的logits结果如下：</p><div class="language-scss vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">scss</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([4</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">.5100</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, -inf, -inf, 6</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">.7500</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, -inf, -inf, -inf, 6</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">.2800</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, -inf])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>最后，我们应用softmax函数将这些值转换为下一个token的概率：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">topk_probas </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.softmax(new_logits, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(topk_probas)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>可以看到，使用Top-3方法的结果是3个非零的概率分数：</p><div class="language-scss vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">scss</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tensor([0</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">.0615</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, 0</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">.0000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, 0</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">.0000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, 0</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">.5775</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, 0</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">.0000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, 0</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">.0000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, 0</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">.0000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, 0</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">.3610</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, 0.0000])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>现在我们可以应用温度缩放和前一节介绍的<code>multinomial</code>函数，在这3个非零概率分数中选择下一个token，以生成下一个token。在下一节中，我们将通过修改文本生成函数来实现这一功能。</p><h3 id="_5-3-3-修改文本生成函数" tabindex="-1">5.3.3 修改文本生成函数 <a class="header-anchor" href="#_5-3-3-修改文本生成函数" aria-label="Permalink to &quot;5.3.3 修改文本生成函数&quot;">​</a></h3><p>前两节介绍了增加LLM生成文本多样性的两个概念：温度采样和Top-k采样。本节中，我们将结合这些概念，修改之前用于LLM文本生成的<code>generate_simple</code>函数，创建一个新的生成函数：</p><p><strong>代码清单5.4</strong> 一个更具多样性的文本生成函数</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> generate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(model, idx, max_new_tokens, context_size, temperature, top_k</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> _ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(max_new_tokens):  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#A</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        idx_cond </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> idx[:, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">context_size:]</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.no_grad():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            logits </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model(idx_cond)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            logits </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> logits[:, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, :]</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> top_k </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> not</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#B</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            top_logits, _ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.topk(logits, top_k)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            min_val </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> top_logits[:, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            logits </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.where(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                logits </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> min_val,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                torch.tensor(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">float</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;-inf&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)).to(logits.device),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                logits</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            )</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> temperature </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#C</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            logits </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> logits </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> temperature</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            probs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.softmax(logits, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            idx_next </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.multinomial(probs, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">num_samples</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        else</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#D</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            idx_next </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.argmax(logits, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">keepdim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        idx </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.cat((idx, idx_next), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> idx</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br></div></div><p>现在让我们看看新的<code>generate</code>函数的效果：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">torch.manual_seed(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">123</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">token_ids </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> generate(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    idx</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">text_to_token_ids(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Every effort moves you&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, tokenizer),</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    max_new_tokens</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">15</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    context_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">GPT_CONFIG_124M</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;context_length&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    top_k</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">25</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    temperature</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.4</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Output text:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, token_ids_to_text(token_ids, tokenizer))</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><p>生成的文本如下：</p><div class="language-vbnet vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">vbnet</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Output text:</span></span>
<span class="line"><span>Every effort moves you stand to work on surprise, a one of us had gone with random</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>可以看到，生成的文本与我们在5.3节开始时通过<code>generate_simple</code>函数生成的文本非常不同（例如“Every effort moves you know,”...），后者是训练集中记忆的一段话。</p><h4 id="练习5-2" tabindex="-1">练习5.2 <a class="header-anchor" href="#练习5-2" aria-label="Permalink to &quot;练习5.2&quot;">​</a></h4><p>尝试使用不同的温度和Top-k设置。根据您的观察，您能想到哪些应用适合较低的温度和Top-k设置？相反，您能想到哪些应用适合较高的温度和Top-k设置吗？（建议在加载OpenAI的预训练权重后重新进行此练习。）</p><h4 id="练习5-3" tabindex="-1">练习5.3 <a class="header-anchor" href="#练习5-3" aria-label="Permalink to &quot;练习5.3&quot;">​</a></h4><p>有哪些不同的设置组合可以使<code>generate</code>函数表现出确定性行为，即禁用随机采样，使其始终生成与<code>generate_simple</code>函数类似的相同输出？</p><p>到目前为止，我们已经介绍了如何预训练LLM并使用它们生成文本。本章的最后两节将讨论如何保存和加载训练好的LLM，以及如何加载OpenAI的预训练权重。</p><h2 id="_5-4-在-pytorch-中加载和保存模型权重" tabindex="-1">5.4 在 PyTorch 中加载和保存模型权重 <a class="header-anchor" href="#_5-4-在-pytorch-中加载和保存模型权重" aria-label="Permalink to &quot;5.4 在 PyTorch 中加载和保存模型权重&quot;">​</a></h2><p>在本章中，我们讨论了如何通过数值评价训练进展并从零开始预训练LLM。虽然LLM和数据集都相对较小，但此练习表明，预训练LLM计算成本极高。因此，能够保存LLM非常重要，这样我们在新会话中使用它时，就不需要每次都重新运行训练过程。</p><p>如图5.16中的章节概述所示，本节我们将介绍如何保存和加载一个预训练模型。在接下来的章节中，我们将从OpenAI加载一个更强大的预训练GPT模型到我们的<code>GPTModel</code>实例中。</p><p>图5.16显示，在训练和检查模型后，保存模型以便以后使用或继续训练往往是有帮助的。本节讲述如何实现这一点，然后在本章最后一节中加载OpenAI的预训练模型权重。 <img src="/assets/image-88.DfmD5iXf.png" alt="alt text"> 幸运的是，保存PyTorch模型相对简单。推荐的方法是保存模型的<code>state_dict</code>（状态字典），它是一个将每一层映射到其参数的字典，可以使用<code>torch.save</code>函数来实现：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">torch.save(model.state_dict(), </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;model.pth&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>在上述代码中，<code>&quot;model.pth&quot;</code>是保存<code>state_dict</code>的文件名。<code>.pth</code>是PyTorch文件的常用扩展名，不过我们实际上可以使用任何文件扩展名。</p><p>然后，在通过<code>state_dict</code>保存模型权重后，我们可以将权重加载到一个新的<code>GPTModel</code>模型实例中：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> GPTModel(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">GPT_CONFIG_124M</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model.load_state_dict(torch.load(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;model.pth&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model.eval()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>如第4章所述，dropout通过在训练期间随机“丢弃”某些层的神经元，帮助模型避免对训练数据的过拟合。然而，在推理期间，我们不希望随机丢弃网络学到的信息。使用<code>model.eval()</code>将模型切换到评估模式，用于推理，这样可以禁用模型中的dropout层。</p><p>如果计划稍后继续预训练模型，例如使用本章定义的<code>train_model_simple</code>函数，建议同时保存优化器状态。</p><p>自适应优化器（如AdamW）为每个模型权重存储额外的参数。AdamW使用历史数据动态调整每个模型参数的学习率。没有这些数据，优化器会重置，导致模型可能无法有效学习，甚至无法正确收敛，从而失去生成连贯文本的能力。使用<code>torch.save</code>，我们可以同时保存模型和优化器的<code>state_dict</code>内容：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">torch.save({</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;model_state_dict&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: model.state_dict(),</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;optimizer_state_dict&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: optimizer.state_dict(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;model_and_optimizer.pth&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>然后，我们可以通过先使用<code>torch.load</code>加载保存的数据，再使用<code>load_state_dict</code>方法恢复模型和优化器状态：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">checkpoint </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.load(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;model_and_optimizer.pth&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> GPTModel(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">GPT_CONFIG_124M</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model.load_state_dict(checkpoint[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;model_state_dict&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">optimizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.optim.AdamW(model.parameters(), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">lr</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5e-4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">weight_decay</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">optimizer.load_state_dict(checkpoint[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;optimizer_state_dict&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model.train()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><h3 id="练习-5-4" tabindex="-1">练习 5.4 <a class="header-anchor" href="#练习-5-4" aria-label="Permalink to &quot;练习 5.4&quot;">​</a></h3><p>在保存权重后，在新的Python会话或Jupyter Notebook文件中加载模型和优化器，并使用<code>train_model_simple</code>函数继续预训练1个轮次。</p><h2 id="_5-5-从-openai-加载预训练权重" tabindex="-1">5.5 从 OpenAI 加载预训练权重 <a class="header-anchor" href="#_5-5-从-openai-加载预训练权重" aria-label="Permalink to &quot;5.5 从 OpenAI 加载预训练权重&quot;">​</a></h2><p>在之前的内容中，为了教育目的，我们使用一个小型数据集（包括短篇故事书）训练了一个小型 GPT-2 模型。此方法使我们能够专注于基础内容，而无需消耗大量时间和计算资源。</p><p>幸运的是，OpenAI 公布了其 GPT-2 模型的权重，使得我们不必花费数十万甚至上百万美元在大规模语料库上重新训练模型。</p><p>在本节的其余部分中，我们将这些权重加载到我们的 <code>GPTModel</code> 类中，并使用模型进行文本生成。这里所指的权重是指存储在 PyTorch 的 <code>Linear</code> 和 <code>Embedding</code> 层的 <code>.weight</code> 属性中的参数。例如，在训练模型时我们通过 <code>model.parameters()</code> 访问了它们。</p><p>在接下来的章节中，我们将重新使用这些预训练权重，为文本分类任务微调模型，并使其遵循类似 ChatGPT 的指令。</p><p>请注意，OpenAI 最初是通过 TensorFlow 保存 GPT-2 权重的，因此我们需要安装 TensorFlow 才能在 Python 中加载这些权重。此外，以下代码将使用 <code>tqdm</code> 进度条工具来跟踪下载过程，也需要安装它。</p><p>你可以在终端中执行以下命令安装这些库：</p><div class="language-bash vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> tensorflo</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">w</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2.15.0</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> tqd</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">m</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4.66</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>下载代码相对较长，主要是一些固定模板代码，并不是特别有趣。因此，我们将直接从本章的在线资源库中下载 <code>gpt_download.py</code> Python 模块，而不是在本章中讨论如何通过 Python 从网络获取文件：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> urllib.request</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">url </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;https://raw.githubusercontent.com/rasbt/&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;LLMs-from-scratch/main/ch05/&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;01_main-chapter-code/gpt_download.py&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">filename </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> url.split(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;/&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)[</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">urllib.request.urlretrieve(url, filename)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>下载此文件后，建议读者简单检查文件内容，以确保文件保存正确且包含有效的 Python 代码。</p><p>现在，我们可以从 <code>gpt_download.py</code> 文件中导入 <code>download_and_load_gpt2</code> 函数，将 GPT-2 架构设置（<code>settings</code>）和权重参数（<code>params</code>）加载到 Python 会话中：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> gpt_download </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> download_and_load_gpt2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">settings, params </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> download_and_load_gpt2(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">model_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;124M&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">models_dir</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;gpt2&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>执行上述代码后，以下与 124M 参数 GPT-2 模型相关的 7 个文件将被下载：</p><div class="language-bash vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">checkpoint:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 100%</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">███████████████████████████</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> 77.0/77.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">63.9kiB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">encoder.json:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 100%</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">█████████████████████████</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> 1.04M/1.04M</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">2.20MiB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">hprams.json:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 100%</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">██████████████████████████</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> 90.0/90.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">78.3kiB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">model.ckpt.data-00000-of-00001:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 100%</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">███████</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> 498M/498M</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [01:09&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">7.16MiB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">model.ckpt.index:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 100%</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">█████████████████████</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> 5.21k/5.21k</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">3.24MiB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">model.ckpt.meta:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 100%</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">██████████████████████</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> 471k/471k</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">2.46MiB/s]</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">vocab.bpe:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 100%</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">████████████████████████████</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> 456k/456k</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [00:00&lt;00:00, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">1.70MiB/s]</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h4 id="更新的下载说明" tabindex="-1">更新的下载说明 <a class="header-anchor" href="#更新的下载说明" aria-label="Permalink to &quot;更新的下载说明&quot;">​</a></h4><p>如果下载代码不起作用，可能是由于网络连接不稳定、服务器问题或 OpenAI 更改了 GPT-2 模型的共享方式。在这种情况下，请访问本章的在线代码资源库：<a href="https://github.com/rasbt/LLMs-from-scratch" target="_blank" rel="noreferrer">https://github.com/rasbt/LLMs-from-scratch</a>，以获取替代的更新说明，并在有疑问时访问 Manning 论坛寻求帮助。</p><p>完成以上代码执行后，我们可以检查 <code>settings</code> 和 <code>params</code> 的内容：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Settings:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, settings)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Parameter dictionary keys:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, params.keys())</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>输出如下：</p><div class="language-css vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">css</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Settings: {&#39;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">n</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">vocab</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&#39;: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">50257</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;n_ctx&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1024</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;n_embd&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">768</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;n_head&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">12</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;n_layer&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">12</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Parameter dictionary keys: dict_keys([</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;blocks&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;b&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;g&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;wpe&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;wte&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p><code>settings</code> 和 <code>params</code> 都是 Python 字典。<code>settings</code> 字典存储了 LLM 架构设置，类似于我们手动定义的 <code>GPT_CONFIG_124M</code> 设置。<code>params</code> 字典包含实际的权重张量。我们仅打印了字典键，因为权重内容太多，如果需要可以通过打印整个字典查看或通过相应的字典键选择个别张量，例如嵌入层权重：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;wte&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Token embedding weight tensor dimensions:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;wte&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].shape)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>输出如下：</p><div class="language-yaml vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">yaml</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">Token embedding weight tensor dimensions</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">(50257, 768)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>通过 <code>download_and_load_gpt2(model_size=&quot;124M&quot;, ...)</code> 设置，我们下载并加载了最小的 GPT-2 模型的权重。不过，OpenAI 还分享了更大模型的权重，如 &quot;355M&quot;、&quot;774M&quot; 和 &quot;1558M&quot;。这些大小不同的 GPT 模型的整体架构相同，如图5.17所示。</p><p>图5.17显示，不同大小的 GPT-2 模型的总体架构保持不变，只是某些结构元素重复的次数不同，嵌入大小不同。本章的其余代码也与这些更大的模型兼容。 <img src="/assets/image-89.DRDrA9aU.png" alt="alt text"> 加载 GPT-2 模型权重到 Python 中后，我们仍需将其从 <code>settings</code> 和 <code>params</code> 字典传递到我们的 <code>GPTModel</code> 实例中。</p><p>首先，我们创建一个字典，列出不同 GPT 模型大小的差异，如图5.17所述：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model_configs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;gpt2-small (124M)&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;emb_dim&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">768</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;n_layers&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">12</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;n_heads&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">12</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">},</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;gpt2-medium (355M)&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;emb_dim&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1024</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;n_layers&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">24</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;n_heads&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">16</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">},</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;gpt2-large (774M)&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;emb_dim&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1280</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;n_layers&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">36</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;n_heads&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">},</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;gpt2-xl (1558M)&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;emb_dim&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1600</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;n_layers&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">48</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;n_heads&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">25</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>假设我们想加载最小的模型，即 &quot;gpt2-small (124M)&quot;。我们可以使用 <code>model_configs</code> 表中的相应设置更新我们之前定义的完整 <code>GPT_CONFIG_124M</code>，如下所示：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model_name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;gpt2-small (124M)&quot;</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">NEW_CONFIG</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> GPT_CONFIG_124M</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.copy()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">NEW_CONFIG</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.update(model_configs[model_name])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>细心的读者可能会记得我们之前使用了256-token的长度，但OpenAI的原始GPT-2模型是用1024-token长度训练的，因此我们还需相应更新<code>NEW_CONFIG</code>：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">NEW_CONFIG</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.update({</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;context_length&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1024</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">})</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>此外，OpenAI在多头注意力模块的线性层中使用了偏置向量来实现查询、键和值矩阵的计算。偏置向量在LLM中已不再常用，因为它们对建模性能没有明显提升，因此可以省略。不过，由于我们使用的是预训练权重，为保持一致性，需要启用这些偏置向量：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">NEW_CONFIG</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.update({</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;qkv_bias&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">})</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>现在，我们可以使用更新后的<code>NEW_CONFIG</code>字典初始化一个新的<code>GPTModel</code>实例：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">gpt </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> GPTModel(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">NEW_CONFIG</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">gpt.eval()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>默认情况下，<code>GPTModel</code>实例会初始化用于预训练的随机权重。使用OpenAI的模型权重的最后一步是用<code>params</code>字典中加载的权重覆盖这些随机权重。</p><p>为此，我们首先定义一个小的<code>assign</code>工具函数，用于检查两个张量或数组（<code>left</code>和<code>right</code>）是否具有相同维度或形状，并将<code>right</code>张量返回为可训练的PyTorch参数：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> assign</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(left, right):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> left.shape </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">!=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> right.shape:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        raise</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> ValueError</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Shape mismatch. Left: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">left.shape</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">, Right: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">right.shape</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn.Parameter(torch.tensor(right))</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>接下来，我们定义<code>load_weights_into_gpt</code>函数，将<code>params</code>字典中的权重加载到<code>GPTModel</code>实例<code>gpt</code>中：</p><p><strong>代码清单5.5</strong> 将OpenAI的权重加载到我们的GPT模型代码中</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> numpy </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> load_weights_into_gpt</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(gpt, params):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    gpt.pos_emb.weight </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(gpt.pos_emb.weight, params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;wpe&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># A</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    gpt.tok_emb.weight </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(gpt.tok_emb.weight, params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;wte&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> b </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;blocks&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])):  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># B</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        q_w, k_w, v_w </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.split(  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># C</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            (params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;blocks&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][b][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;attn&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;c_attn&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;w&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">axis</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        gpt.trf_blocks[b].att.W_query.weight </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            gpt.trf_blocks[b].att.W_query.weight, q_w.T)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        gpt.trf_blocks[b].att.W_key.weight </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            gpt.trf_blocks[b].att.W_key.weight, k_w.T)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        gpt.trf_blocks[b].att.W_value.weight </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            gpt.trf_blocks[b].att.W_value.weight, v_w.T)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        q_b, k_b, v_b </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.split(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            (params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;blocks&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][b][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;attn&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;c_attn&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;b&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">axis</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        gpt.trf_blocks[b].att.W_query.bias </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            gpt.trf_blocks[b].att.W_query.bias, q_b)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        gpt.trf_blocks[b].att.W_key.bias </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            gpt.trf_blocks[b].att.W_key.bias, k_b)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        gpt.trf_blocks[b].att.W_value.bias </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            gpt.trf_blocks[b].att.W_value.bias, v_b)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        gpt.trf_blocks[b].att.out_proj.weight </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            gpt.trf_blocks[b].att.out_proj.weight,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;blocks&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][b][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;attn&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;c_proj&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;w&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].T)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        gpt.trf_blocks[b].att.out_proj.bias </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            gpt.trf_blocks[b].att.out_proj.bias,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;blocks&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][b][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;attn&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;c_proj&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;b&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        gpt.trf_blocks[b].ff.layers[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].weight </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            gpt.trf_blocks[b].ff.layers[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].weight,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;blocks&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][b][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;mlp&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;c_fc&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;w&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].T)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        gpt.trf_blocks[b].ff.layers[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].bias </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            gpt.trf_blocks[b].ff.layers[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].bias,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;blocks&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][b][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;mlp&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;c_fc&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;b&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        gpt.trf_blocks[b].ff.layers[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].weight </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            gpt.trf_blocks[b].ff.layers[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].weight,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;blocks&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][b][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;mlp&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;c_proj&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;w&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].T)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        gpt.trf_blocks[b].ff.layers[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].bias </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            gpt.trf_blocks[b].ff.layers[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].bias,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;blocks&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][b][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;mlp&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;c_proj&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;b&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        gpt.trf_blocks[b].norm1.scale </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            gpt.trf_blocks[b].norm1.scale,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;blocks&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][b][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;ln_1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;g&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        gpt.trf_blocks[b].norm1.shift </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            gpt.trf_blocks[b].norm1.shift,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;blocks&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][b][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;ln_1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;b&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        gpt.trf_blocks[b].norm2.scale </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            gpt.trf_blocks[b].norm2.scale,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;blocks&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][b][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;ln_2&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;g&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        gpt.trf_blocks[b].norm2.shift </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            gpt.trf_blocks[b].norm2.shift,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;blocks&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][b][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;ln_2&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;b&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    gpt.final_norm.scale </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(gpt.final_norm.scale, params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;g&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    gpt.final_norm.shift </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(gpt.final_norm.shift, params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;b&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    gpt.out_head.weight </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assign(gpt.out_head.weight, params[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;wte&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># D</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br></div></div><p>在<code>load_weights_into_gpt</code>函数中，我们仔细匹配OpenAI实现中的权重和我们的<code>GPTModel</code>实现。比如，OpenAI将第一个transformer块的输出投影层的权重张量存储为<code>params[&quot;blocks&quot;][0][&quot;attn&quot;][&quot;c_proj&quot;][&quot;w&quot;]</code>。在我们的实现中，该权重张量对应于<code>gpt.trf_blocks[b].att.out_proj.weight</code>，其中<code>gpt</code>是一个<code>GPTModel</code>实例。</p><p>开发<code>load_weights_into_gpt</code>函数花费了大量时间，因为OpenAI使用的命名方式与我们的略有不同。但是，如果我们尝试匹配两个形状不同的张量，<code>assign</code>函数会发出警告。此外，如果我们在此函数中出错，结果GPT模型将无法生成连贯的文本，我们可以通过测试输出来验证是否正确加载了模型权重。</p><p>接下来，我们将<code>load_weights_into_gpt</code>应用于实践，将OpenAI的模型权重加载到我们的<code>GPTModel</code>实例<code>gpt</code>中：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">load_weights_into_gpt(gpt, params)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">gpt.to(device)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>如果模型加载成功，我们现在可以使用它并通过之前的<code>generate</code>函数生成新文本：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">torch.manual_seed(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">123</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">token_ids </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> generate(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">gpt,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    idx</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">text_to_token_ids(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Every effort moves you&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, tokenizer),</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    max_new_tokens</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">25</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    context_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">NEW_CONFIG</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;context_length&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    top_k</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">50</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    temperature</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.5</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Output text:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, token_ids_to_text(token_ids, tokenizer))</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><p>生成的文本如下：</p><div class="language-vbnet vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">vbnet</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Output text:</span></span>
<span class="line"><span>Every effort moves you toward finding an ideal new way to practice something!</span></span>
<span class="line"><span>What makes us want to be on top of that?</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>我们可以确认模型权重已正确加载，因为模型能够生成连贯的文本。在这一过程中，即使有微小的错误也会导致模型无法正常生成。</p><p>在接下来的章节中，我们将进一步处理此预训练模型，并微调它以用于文本分类和遵循指令。</p><h4 id="练习-5-5" tabindex="-1">练习 5.5 <a class="header-anchor" href="#练习-5-5" aria-label="Permalink to &quot;练习 5.5&quot;">​</a></h4><p>计算具有OpenAI预训练权重的<code>GPTModel</code>在“<code>The Verdict</code>”数据集上的训练和验证集损失。</p><h4 id="练习-5-6" tabindex="-1">练习 5.6 <a class="header-anchor" href="#练习-5-6" aria-label="Permalink to &quot;练习 5.6&quot;">​</a></h4><p>建议读者尝试使用不同大小的 GPT-2 模型，例如最大的1558M参数模型，并将生成的文本与本章加载的124M模型进行比较。</p><h2 id="_5-6-总结" tabindex="-1">5.6 总结 <a class="header-anchor" href="#_5-6-总结" aria-label="Permalink to &quot;5.6 总结&quot;">​</a></h2><ul><li>当大语言模型 (LLM) 生成文本时，它是逐个token地生成的。</li><li>默认情况下，下一个token的生成是通过将模型输出转换为概率分数，并从词汇表中选择对应于最高概率分数的token，这称为“贪婪解码”。</li><li>通过使用概率采样和温度缩放，我们可以影响生成文本的多样性和连贯性。</li><li>在训练过程中，训练集和验证集的损失可以用来评估LLM生成文本的质量。</li><li>预训练LLM的过程涉及调整模型权重以最小化训练损失。</li><li>LLM的训练循环是深度学习中的标准流程，使用传统的交叉熵损失和AdamW优化器。</li><li>在大型文本语料库上预训练LLM需要大量时间和资源，因此，我们可以加载OpenAI公开提供的权重，作为在大型数据集上自行预训练模型的替代方案。</li></ul></div></div></main><footer class="VPDocFooter" data-v-56ee120b data-v-d7c1e045><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-d7c1e045><span class="visually-hidden" id="doc-footer-aria-label" data-v-d7c1e045>Pager</span><div class="pager" data-v-d7c1e045><a class="VPLink link pager-link prev" href="./bllm/4_implementing_a_gpt_model_from_scratch_to_generate_text.html" data-v-d7c1e045><!--[--><span class="desc" data-v-d7c1e045>Previous page</span><span class="title" data-v-d7c1e045>从零实现GPT模型生成文本</span><!--]--></a></div><div class="pager" data-v-d7c1e045><a class="VPLink link pager-link next" href="./bllm/appendix_a_introduction_to_pytorch.html" data-v-d7c1e045><!--[--><span class="desc" data-v-d7c1e045>Next page</span><span class="title" data-v-d7c1e045>附录 A. PyTorch简介</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api-examples.md\":\"B6hxRtHa\",\"bllm_1_understanding_large_language_models.md\":\"B2I0VYZf\",\"bllm_2_working_with_text_data.md\":\"B0Pbt0AC\",\"bllm_3_coding_attention_mechanisms.md\":\"B47eLHic\",\"bllm_4_implementing_a_gpt_model_from_scratch_to_generate_text.md\":\"D__J2eJa\",\"bllm_5_pretraining_on_unlabeled_data.md\":\"DJ9O5TGa\",\"bllm_appendix_a_introduction_to_pytorch.md\":\"Cg7eem40\",\"bllm_appendix_b_references_and_further_reading.md\":\"OjJjfrsB\",\"bllm_appendix_c_exercise_solutions.md\":\"BHzWBbEn\",\"bllm_appendix_d_adding_bells_and_whistles_to_the_training_loop.md\":\"CSDNs3Ym\",\"bllm_index.md\":\"CCUQ-BEG\",\"index.md\":\"DUXEVjN4\",\"markdown-examples.md\":\"C_OxCkrE\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"大模型知识库\",\"description\":\"A VitePress Site\",\"base\":\"./\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"首页\",\"link\":\"/\"},{\"text\":\"示例\",\"link\":\"/markdown-examples\"}],\"search\":{\"provider\":\"local\"},\"sidebar\":[{\"text\":\"书籍\",\"items\":[{\"text\":\"Markdown Examples\",\"link\":\"/markdown-examples\"},{\"text\":\"Runtime API Examples\",\"link\":\"/api-examples\"},{\"text\":\"欢迎\",\"link\":\"/bllm/\"},{\"text\":\"理解大型语言模型\",\"link\":\"/bllm/1_understanding_large_language_models\"},{\"text\":\"处理文本数据\",\"link\":\"/bllm/2_working_with_text_data\"},{\"text\":\"编写注意力机制\",\"link\":\"/bllm/3_coding_attention_mechanisms\"},{\"text\":\"从零实现GPT模型生成文本\",\"link\":\"/bllm/4_implementing_a_gpt_model_from_scratch_to_generate_text\"},{\"text\":\" 在无标签数据上预训练\",\"link\":\"/bllm/5_pretraining_on_unlabeled_data\"},{\"text\":\"附录 A. PyTorch简介\",\"link\":\"/bllm/appendix_a_introduction_to_pytorch\"},{\"text\":\"附录 B. 参考文献与进一步阅读\",\"link\":\"/bllm/appendix_b_references_and_further_reading\"},{\"text\":\"附录 C. 习题解答\",\"link\":\"/bllm/appendix_c_exercise_solutions\"},{\"text\":\"附录 D. 给训练循环添加附加功能\",\"link\":\"/bllm/appendix_d_adding_bells_and_whistles_to_the_training_loop\"}]},{\"text\":\"课程\",\"items\":[{\"text\":\"课程1\",\"link\":\"/course/1\"},{\"text\":\"课程2\",\"link\":\"/course/2\"}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/vuejs/vitepress\"}]},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>